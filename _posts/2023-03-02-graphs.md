---
title: 'Graph Attention Networks'
description: An inplementation.
featured_image: '/images/demo/demo-square.jpg'
---

![]()

Graph Networks have been around for quite a while, and there are plenty of sources online that can give you a good overview. <br>This [lesson](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial7/GNN_overview.html) from <b>UvA Deep Learning Tutorials</b> is a great start. 

But often, the implementation gets quite a handful, and as a result, people skip. ðŸ˜ž 

So this one is more of an implementation-only. Here we get the basic Graph Convolutional Layer, and the Graph Attention Layer, <b>multi-headed</b>! Hehe! 

### Graph Convolutional Layer
```python
class GCNLayer(nn.Module) :

    def __init__(self, d_in, d_out) :
        super().__init__()
        self.projection = nn.Linear(d_in, d_out)

    def forward(self, x, adj_hat) :
        # x : Node features : batch, n_nodes, c_in
        # adj_hat : adj matrix with self connections : batch, n_nodes, n_nodes

        x = self.projection(x)
        x = torch.bmm(adj_hat, x)
        x = x / adj_hat.sum(dim = -1, keepdims = True)

        return x 
```
